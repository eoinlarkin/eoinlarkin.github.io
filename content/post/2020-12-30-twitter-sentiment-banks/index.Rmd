---
title: Sentiment Analysis of Tweets to Irish Banks
author: Eoin
date: '2020-02-01'
slug: twitter-sentiment-banks
categories: []
tags: []
---

## Twitter Sentiment Analysis

Analysing sentiment based on a text string is pretty classic introductory problem in the field of Machine Learning.

The idea is seductively simple - by analysing the data of publically available tweets is it possible to discern or extrapolate some additional analysis.

Nevertheless the analysis does provide the opportunity to plot some pretty graphs


### Objective


### Twitter Accounts
Bank of Ireland operate two profiles on Twitter – the first @bankofireland is utilised to promote the Bank of Ireland brand. (primary account). The second @talktoboi (support account) allows users to directly contact Bank of Ireland support staff to resolve issues.

This is a similar approach adopted by AIB – the following table provides an overview of the accounts operated by both BOI and AIB: 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, results='asis', echo=FALSE}
acc <- c('@bankofireland','@talktoboi','@aibireland', '@askaib')
acc.type <-c('Primary','Customer Support','Primary', 'Customer Support')
acc.foll <- c('39.3k','41.3k','30.9k', '43k')
acc.desc <- c('Official AIB Twitter profile. Primarily used to promote the Bank of Ireland                  brand on Twitter', 'Bank of Ireland’s Twitter customer support channel. Used to manage queries directed to Bank of Ireland customer support queries', 'Official AIB Twitter profile. Primarily used to promote the AIB brand on Twitter', 'Official AIB Support channel. Customer queries are directed to this twitter account and resolved by AIB’s dedicated Twitter customer care team') 
              
df <- data.frame(acc, acc.type, acc.foll, acc.desc)
knitr::kable(df, caption='Summary of Twitter Accounts')
```




```{r include=FALSE}

rm(list=ls())     #clearing the R environment

setwd("C:/Users/Eoin/OneDrive/Data Science/Projects/Tweet Analysis")


library(httpuv)       # required for authentication
library(rtweet)       # loading rtweet library
library(ggplot2)      # plotting 
library(dplyr)        # pipes
library(tidytext)     # text mining library
library(lubridate)

```


```{r include=FALSE, eval=FALSE}

# ------------------------------- 
# Setting up twitter 
# -------------------------------
appname <- "api_test_explore"      # name of twitter app
key <- "re6VqRcF0SmXDlxPR4I1xeWwg"     # twitter api key
secret <- "WddFVgjpGGUvErcRJGcbaAkRi1D0a7J5VhG5I2uIftO9FcG6lM"   # api secret key
access_tok <- "1125852423287922689-nQN6HOeTpgkFZHzFDc3qVF8kxEJqiw"
access_sec <- "tk1IjdZGaC1VIGhdCmMyZoEPGgi6QnfcEd40GYReG9nrX"


# create token named "twitter_token"
#token <- create_token(
#  app = appname,
#  consumer_key = key,
#  consumer_secret = secret)

get_token() # Testing token

```


```{r include=FALSE, eval=FALSE}
boi_main_timeline <- get_timeline("bankofireland", n = 18000)
aib_main_timeline <- get_timeline("aibireland", n = 18000)
boi_support_timeline <- get_timeline("talktoboi", n = 18000)
aib_support_timeline <- get_timeline("askaib", n = 18000)

tweets_to_boi_support <- search_30day('@talktoBOI', n = 1000, env_name = 'Staging')
tweets_to_aib_support <- search_30day('@AskAIB', n=1000, env_name = 'Staging')
tweets_to_boi_main <- search_30day('@bankofireland',n = 5000, env_name = 'Staging')
tweets_to_aib <- search_30day('@aibireland', n = 5000, env_name = 'Staging')

# Downloading Tweets

save_as_csv(boi_main_timeline, '_raw_boi_main_timeline.csv')
save_as_csv(aib_main_timeline, '_raw_aib_main_timeline.csv')
save_as_csv(boi_support_timeline, '_raw_boi_support_timeline.csv')
save_as_csv(aib_support_timeline, '_raw_aib_support_timeline.csv')
save_as_csv(tweets_to_boi_support, '_raw_tweets_to_boi_support.csv')
save_as_csv(tweets_to_aib_support, '_raw_tweets_to_aib_support.csv')
save_as_csv(tweets_to_boi_main, '_raw_tweets_to_boi_main.csv')
save_as_csv(tweets_to_aib, '_raw_tweets_to_aib.csv')
```



```{r include=FALSE,eval=FALSE}
setwd("C:/Users/Eoin/OneDrive/Data Science/Projects/Tweet Analysis")


boi_timeline <- read_twitter_csv('_raw_boi_main_timeline.csv')
aib_timeline <- read_twitter_csv('_raw_aib_main_timeline.csv')

tweets_aib <- read_twitter_csv('_raw_tweets_to_aib_support.csv')
tweets_boi <- read_twitter_csv('_raw_tweets_to_boi_support.csv')

tweets_30day_aib <- read_twitter_csv('_raw_tweets_to_aib.csv') %>%
                    filter(screen_name != 'AskAIB')
    
tweets_30day_boi <- read_twitter_csv('_raw_tweets_to_boi_main.csv') %>%
                    filter(screen_name != 'talktoBOI')

filter_date <- '2019-07-08'

# Cleaining up the text in the tweets
boi_timeline$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", boi_timeline$text))
aib_timeline$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", aib_timeline$text))
tweets_aib$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", tweets_aib$text))
tweets_boi$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", tweets_boi$text))
tweets_30day_aib$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", tweets_30day_aib$text))
tweets_30day_boi$text_clean = plain_tweets(gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)", "", tweets_30day_boi$text)) 


# ***************************************************
# Plotting AIB / BOI Output over a four month window
# ***************************************************


# Converting the date into weekly blocks
boi_timeline$date_week <- data.frame(as.Date(floor_date(boi_timeline$created_at, unit = "week")))
names(boi_timeline$date_week) = "date_week"
aib_timeline$date_week <- data.frame(as.Date(floor_date(aib_timeline$created_at, unit = "week")))
names(aib_timeline$date_week) = "date_week"

boi_by_week <- as_tibble(boi_timeline$date_week) %>%
  filter(date_week >= '2019-07-14' & date_week <= '2019-10-13') %>%
  group_by(date_week) %>%
  summarise(cnt = n()) %>%
  mutate(account = '@bankofireland')

aib_by_week <- as_tibble(aib_timeline$date_week) %>%
  filter(date_week >= '2019-07-14' & date_week <= '2019-10-13') %>%
  group_by(date_week) %>%
  summarise(cnt = n()) %>%
  mutate(account = '@aibireland')


ggplot(rbind(aib_by_week, boi_by_week), aes(x=date_week, y=cnt, fill= account)) +
  geom_bar(stat="identity", position="dodge", color='white')+
  labs(x="Weekly Block", y="Tweet Count") +
  scale_x_date(breaks = '1 weeks', date_labels = "%b-%d") +
  ggtitle("Tweet Activity per Week") + 
  scale_fill_manual("Account", values = c("@aibireland" = "mediumpurple4", "@bankofireland" = "dodgerblue4")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) 

ggsave("tweet_activity_per_week.png", width = 10, height = 6, units = "in", dpi=200)

# ***************************************************
# Getting top 5 tweets -> last four months
# ***************************************************

top_tweet_boi <- boi_timeline %>%
  filter(created_at >= '2019-07-08') %>%
  filter(dense_rank(-favorite_count) <= 5)  %>%
  arrange(desc(favorite_count))
top_tweet_boi <- top_tweet_boi[c("created_at","text_clean","favorite_count", "retweet_count")]
top_tweet_boi$created_at <- format(top_tweet_boi$created_at, "%b-%d")

top_tweet_aib <- aib_timeline %>%
  filter(created_at >= '2019-07-08') %>%
  filter(dense_rank(-favorite_count) <= 5)  %>%
  arrange(desc(favorite_count))
top_tweet_aib <- top_tweet_aib[c("created_at","text_clean","favorite_count", "retweet_count")]
top_tweet_aib$created_at <- format(top_tweet_aib$created_at, "%b-%d")

top_viral_boi <- boi_timeline %>%
  filter(created_at >= '2019-07-08') %>%
  filter(dense_rank(-retweet_count) <= 5)  %>%
  arrange(desc(retweet_count))
top_viral_boi <- top_viral_boi[c("created_at","text_clean","favorite_count", "retweet_count")]
top_viral_boi$created_at <- format(top_viral_boi$created_at, "%b-%d")

top_viral_aib <- aib_timeline %>%
  filter(created_at >= filter_date) %>%
  filter(dense_rank(-retweet_count) <= 5) %>%
  arrange(desc(retweet_count))
top_viral_aib <- top_viral_aib[c("created_at","text_clean","favorite_count", "retweet_count")]
top_viral_aib$created_at <- format(top_viral_aib$created_at, "%b-%d")

write.csv(top_viral_aib,"top_viral_aib.csv")
write.csv(top_viral_boi,"top_viral_boi.csv")
write.csv(top_tweet_aib,"top_tweet_aib.csv")
write.csv(top_tweet_boi,"top_tweet_boi.csv")


# ***************************************************
# Device analysis - last 30 days - Main Accounts
# ***************************************************


tweets_30day_boi_source <- as_tibble(tweets_30day_boi$source) %>%
  group_by(value) %>%
  summarise(cnt = n()) %>%
  mutate(perc = cnt / sum(cnt)) %>%
  filter(perc >= 0.01) %>%
  mutate(account = '@bankofireland')

tweets_30day_aib_source <- as_tibble(tweets_30day_aib$source) %>%
  group_by(value) %>%
  summarise(cnt = n()) %>%
  mutate(perc = cnt / sum(cnt)) %>%
  filter(perc >= 0.01) %>%
  mutate(account = '@aibireland')



ggplot(rbind(tweets_30day_aib_source, tweets_30day_boi_source), aes(x=value, y=perc, fill=account)) +
  geom_bar(stat="identity", position="dodge", color='white')+
  labs(x="Application", y="% of all Tweets") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Last 30 Days - Application used by individuals tweeting to account") + 
  scale_fill_manual("Account", values = c("@aibireland" = "mediumpurple4", "@bankofireland" = "dodgerblue4")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) 
  
ggsave("device_used_for_tweets.png", width = 10, height = 6, units = "in", dpi=200)

# ***************************************************
# Place location - last 30 days - Main Accounts
# ***************************************************

boi_loc <- as_tibble(tweets_30day_boi$location) %>%
  group_by(value) %>%
  summarise(cnt = n()) %>%
  mutate(perc = cnt / sum(cnt)) %>%
  mutate(account = '@bankofireland') %>%
  filter(perc >= 0.01) 
  
aib_loc <- as_tibble(tweets_30day_aib$location) %>%
  group_by(value) %>%
  summarise(cnt = n()) %>%
  mutate(perc = cnt / sum(cnt)) %>%
  mutate(account = '@aibireland') %>%
  filter(perc >= 0.01) 

ggplot(rbind(aib_loc, boi_loc), aes(x=value, y=perc, fill= account)) +
  geom_bar(stat="identity", position="dodge", color='white')+
  labs(x = "", y="% of all Tweets") +
  scale_y_continuous(labels = scales::percent) +
  ggtitle("Last 30 Days: Origin of tweets") + 
  scale_fill_manual("Account", values = c("@aibireland" = "mediumpurple4", "@bankofireland" = "dodgerblue4")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) 

ggsave("tweet_origin_main_accounts.png", width = 10, height = 6, units = "in", dpi=100)


india_tweets <- as_tibble(tweets_30day_aib) %>%
  filter(location == 'G B Nagar, Uttar Pradesh India') 
# Seems to be a nusicance account



# ***************************************************
# Location analysis - last 30 days - Main Accounts
# ***************************************************

loc_data_boi<- lat_lng(tweets_30day_boi)

install.packages('rworldmap')
library(rworldmap)
newmap <- getMap(resolution = "li")
plot(newmap, xlim = c(-10, 20), ylim = c(50, 50), asp = 1)
points(loc_data_boi$lng, loc_data_boi$lat, col = "dodgerblue4", cex = .6)


# ***************************************************************
# Support Tweets - plotting most frequent workds
# These plots are a sample of 1,000 tweets over the last 30 days
# ***************************************************************

# plot the top 15 words
custom_words <- as.data.frame(c('aibireland','boi', 'talktoboi', 'bankofireland', 'bank', 'askaib'), stringsAsFactors=FALSE)
colnames(custom_words) <- 'word'

#test <- as.data.frame(tweets_aib$text_clean) #tweets for testing


# plotting the top words boi
tweets_boi %>%
  filter(created_at >= filter_date) %>%
  dplyr::select(text_clean) %>%
  unnest_tokens(word, text_clean) %>% 
  anti_join(stop_words) %>%
  anti_join(custom_words) %>%
  count(word, sort = TRUE) %>%
  top_n(25) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col(fill="dodgerblue4") +
  xlab(NULL) +
  coord_flip() +
  labs(x = "Unique Words",
       y = "Count",
       title = "@Talktoboi - High frequency words in tweets")

ggsave("frequent_words_boi.png", width = 10, height = 6, units = "in", dpi=200)


# plotting the top words
tweets_aib %>%
  filter(created_at >= filter_date) %>%
  filter(screen_name != 'EBSSVRCampaign') %>%
  dplyr::select(text_clean) %>%
  unnest_tokens(word, text_clean) %>% 
  anti_join(stop_words) %>%
  anti_join(custom_words) %>%
  count(word, sort = TRUE) %>%
  top_n(25) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col(fill="mediumpurple4") +
  xlab(NULL) +
  coord_flip() +
  labs(x = "Unique Words",
       y = "Count",
       title = "@Askaib - High frequency words in tweets")

ggsave("frequent_words_aib.png", width = 10, height = 6, units = "in", dpi=200)

write.csv(tweets_boi$text_clean,"tweets_to_boi_support.csv")
write.csv(tweets_aib$text_clean,"tweets_to_aib_support.csv")

# ***************************************************************
# Sentiment Analysis by Day 
# BOI main account - average daily sentiment
# ***************************************************************

# Using the following webpage for inspiration
# https://dataaspirant.com/2018/03/22/twitter-sentiment-analysis-using-r/

library("SnowballC")
library("tm")
library("syuzhet")
library('wesanderson')

boi_tweets_sent <- tweets_30day_boi$text_clean
aib_tweets_sent <- tweets_30day_aib$text_clean
word.boi <- as.vector(boi_tweets_sent)
word.aib <- as.vector(aib_tweets_sent)

?get_sentiment()

sent.value_boi <- get_sentiment(word.boi)
sent.value_aib <- get_sentiment(word.aib)



# Most positive tweet
most.positive_boi <- word.boi[sent.value_boi == max(sent.value_boi)]
most.positive_boi

most.positive_aib <- word.aib[sent.value_aib == max(sent.value_aib)]
most.positive_aib

category_sent_boi <- ifelse(sent.value_boi < 0, "Negative", ifelse(sent.value_boi > 0, "Positive", "Neutral"))
df_sent_boi <- cbind.data.frame(tweets_30day_boi$created_at, word.boi,sent.value_boi,category_sent_boi)
colnames(df_sent_boi) <- c('date', 'tweet', 'sentiment_score', 'sentiment_category')

category_sent_aib <- ifelse(sent.value_aib < 0, "Negative", ifelse(sent.value_aib > 0, "Positive", "Neutral"))
df_sent_aib <- cbind.data.frame(tweets_30day_aib$created_at, word.aib,sent.value_aib,category_sent_aib)
colnames(df_sent_aib) <- c('date', 'tweet', 'sentiment_score', 'sentiment_category')


 as_tibble(df_sent_boi) %>%
  mutate(date = floor_date(date, unit = "day")) %>%
  group_by(date, sentiment_category) %>%
  summarise(cnt = n()) %>%
  mutate(perc = cnt / sum(cnt)) %>%
  ggplot(aes(x=date, y=perc, group=sentiment_category, color = sentiment_category)) +
  geom_line(size=1) +
  geom_point() +
  scale_y_continuous(labels = scales::percent) +
  scale_color_manual(values=c('#D16103', '#4E84C4', '#52854C')) + #wes_palette(n=3, name="Darjeeling1")) +
   labs(x = "Date",
        y = "Percentage of Tweets",
        title = "@bankofireland - Sentiment Analysis over 30 Day Period")
 
 ggsave("sentiment_boi.png", width = 10, height = 6, units = "in", dpi=200)
 
 as_tibble(df_sent_aib) %>%
   mutate(date = floor_date(date, unit = "day")) %>%
   group_by(date, sentiment_category) %>%
   summarise(cnt = n()) %>%
   mutate(perc = cnt / sum(cnt)) %>%
   ggplot(aes(x=date, y=perc, group=sentiment_category, color = sentiment_category)) +
   geom_line(size=1) +
   geom_point() +
   scale_y_continuous(labels = scales::percent) +
   scale_color_manual(values=c('#D16103', '#4E84C4', '#52854C')) + #wes_palette(n=3, name="Darjeeling1")) +
   labs(x = "Date",
        y = "Percentage of Tweets",
        title = "@aibireland - Sentiment Analysis over 30 Day Period")
 
 ggsave("sentiment_aib.png", width = 10, height = 6, units = "in", dpi=200)
 
 
  
 x <- as_tibble(df_sent_boi) %>%
   mutate(date = floor_date(date, unit = "day")) %>%
   group_by(date, sentiment_category) %>%
   summarise(cnt = n()) %>%
   mutate(perc = cnt / sum(cnt))
 
 mean(x[sentiment_category=='positive'])
 
 mean(x$perc[x$sentiment_category=='Positive'])
 mean(x$perc[x$sentiment_category=='Negative'])
 
  
 # ***************************************************************
 # Emotion Analysis by Day 
 #  # ***************************************************************  
 
 
 emotion.boi <- get_nrc_sentiment(word.boi)
 emotion.boi_2 <- cbind(boi_tweets_sent, emotion.boi) 
 
```

 